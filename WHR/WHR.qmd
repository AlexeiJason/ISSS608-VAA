---
title: "WHR"
---

# Data Preparation

## Importing packages

```{r}
pacman::p_load(skimr,tidyverse, patchwork, readr, dplyr, plotly, ggridges, ggiraph, ggthemes,corrplot,GGally)
```

## Importing Datasets

```{r}
WHRdata2015 = read.csv ("data/WHRdata2015.csv")
WHRdata2016 = read.csv ("data/WHRdata2016.csv")
WHRdata2017 = read.csv ("data/WHRdata2017.csv")
WHRdata2018 = read.csv ("data/WHRdata2018.csv")
WHRdata2019 = read.csv ("data/WHRdata2019.csv")
head(WHRdata2019)
```

## Rename all the column so the column name are same (so we can combine all the datasets together). I rename them based on columns at year 2017.

```{r}
WHRdata2019=plyr::rename(WHRdata2019, replace = c( "Country.or.region"="Country", 
                                  "Overall.rank"="Happiness.Rank" ,
                                  "GDP.per.capita"="Economy..GDP.per.Capita.",
                                  "Healthy.life.expectancy"="Health..Life.Expectancy.",
                                  "Freedom.to.make.life.choices"="Freedom",
                                  "Perceptions.of.corruption"="Trust..Government.Corruption.",
                                  "Social.support"="Family",
                                  "Score"="Happiness.Score"))
colnames(WHRdata2019)
```

```{r}
WHRdata2018=plyr::rename(WHRdata2018, replace = c( "Country.or.region"="Country", 
                                  "Overall.rank"="Happiness.Rank" ,
                                  "GDP.per.capita"="Economy..GDP.per.Capita.",
                                  "Healthy.life.expectancy"="Health..Life.Expectancy.",
                                  "Freedom.to.make.life.choices"="Freedom",
                                  "Perceptions.of.corruption"="Trust..Government.Corruption.",
                                  "Social.support"="Family",
                                  "Score"="Happiness.Score"))
colnames(WHRdata2018)
```

```{r}
WHRdata2015=plyr::rename(WHRdata2015, replace = c( "Happiness Rank" = "Happiness.Rank", 
                                  "Happiness Score" = "Happiness.Score",
                                  "Economy (GDP per Capita)" = "Economy..GDP.per.Capita.",
                                  "Health (Life Expectancy)" = "Health..Life.Expectancy.",
                                  "Trust (Government Corruption)" = "Trust..Government.Corruption.",
                                  "Dystopia Residual"="Dystopia.Residual"
                                  ))
colnames(WHRdata2015)
```

```{r}
WHRdata2016=plyr::rename(WHRdata2016, replace = c( "Happiness Rank" = "Happiness.Rank", 
                                  "Happiness Score" = "Happiness.Score",
                                  "Economy (GDP per Capita)" = "Economy..GDP.per.Capita.",
                                  "Health (Life Expectancy)" = "Health..Life.Expectancy.",
                                  "Trust (Government Corruption)"  = "Trust..Government.Corruption.",
                                  "Dystopia Residual"="Dystopia.Residual"
                                  ))
colnames(WHRdata2016)
```

## I put a column called 'Year' to identify every data set year. So later when I combine all the data sets, there will be column called year which identify that year's data.

```{r}
WHRdata2015<-cbind(Year=2015,WHRdata2015)

WHRdata2016<-cbind(Year=2016,WHRdata2016)

WHRdata2017<-cbind(Year=2017,WHRdata2017)

WHRdata2018<-cbind(Year=2018,WHRdata2018)

WHRdata2019<-cbind(Year=2019,WHRdata2019)
```

## Changing the data type of 'Trust..Government.Corruption.' from year 2018 to the correct data type which is numeric.

```{r}
WHRdata2018$Trust..Government.Corruption. = as.numeric(WHRdata2018$Trust..Government.Corruption.)

str(WHRdata2018)
```

## Combining all the data sets.

```{r}
WHRdata20152016<-dplyr::bind_rows(WHRdata2015,WHRdata2016)

WHRdata201520162017<-dplyr::bind_rows(WHRdata20152016,WHRdata2017)

WHRdata20182019<-dplyr::bind_rows(WHRdata2018,WHRdata2019)

WHRdata<-dplyr::bind_rows(WHRdata201520162017,WHRdata20182019)
head(WHRdata)
```

## Changing the data type of 'Happiness.Rank' to numeric for further analysis.

```{r}
WHRdata$Happiness.Rank  = as.numeric(WHRdata$Happiness.Rank )

str(WHRdata)
```

## Checking missing values.

```{r}
colSums(is.na(WHRdata))
```

## Remove unnecessary column containing missing values.

```{r}
WHRdata = subset(WHRdata, select = -c(Lower.Confidence.Interval,Upper.Confidence.Interval,Dystopia.Residual,Standard.Error,Whisker.high,Whisker.low))

colSums(is.na(WHRdata))
```

## Imputing missing value with median for the 'Trust..Government.Corruption.

```{r}
WHRdata$Trust..Government.Corruption.[is.na(WHRdata$Trust..Government.Corruption.)] <- median(WHRdata$Trust..Government.Corruption., na.rm = T)

colSums(is.na(WHRdata))
```

We are going to check how many countries for each year then we are going to filter uncommon data in Country Column due to the data is describing the happiness score and relative factors for countries across different years. So, it is important to view the uniformity of the data in Year column of the data.

```{r}
aggregate(WHRdata$Country, by=list(WHRdata$Year), FUN=length)

```

From the table shown as above, the number of countries involved in this dataset for different year is different. Therefore, it is necessary to make an intersection of them to get the most common country list.

```{r}
Country_2015 = subset(WHRdata, Year == 2015)$Country
Country_2016 = subset(WHRdata, Year == 2016)$Country
Country_2017 = subset(WHRdata, Year == 2017)$Country
Country_2018 = subset(WHRdata, Year == 2018)$Country
Country_2019 = subset(WHRdata, Year == 2019)$Country
```

```{r}
common_country =intersect(intersect(intersect(intersect(Country_2015,
Country_2016),Country_2017),Country_2018),Country_2019)
length(common_country)
```

Therefore, there are 141 countriesâ€™ data existing across from 2015-2019 in this dataset.Then we need to filter the original dataset by this common_country list.

```{r}
WHRdata_cleaned = subset(WHRdata,Country %in% common_country)
print(paste("The amount of rows in the dataset is: ",dim(WHRdata_cleaned)[1]))
print(paste("The amount of columns in the dataset is: ",dim(WHRdata_cleaned)[2]))
```

Create a new dataset for storing common region and country

```{r}
common_region <- unique(subset(WHRdata_cleaned, Region!="NA", c(Country, Region)))

head(common_country)
```

Fill relate region to missing value of region column

```{r}
assign_region <- function(x){
  Region <- common_region$Region[common_region$Country == x]
}

for(country in common_country)
      WHRdata_cleaned$Region[WHRdata_cleaned$Country == country] <- assign_region(country)
```

Rename all the column to better collumn-name for further anlaysis.

```{r}
WHRdata_cleaned=plyr::rename(WHRdata_cleaned, replace = c( 
                                  "Economy..GDP.per.Capita."="GDP.per.Capita",
                                  "Health..Life.Expectancy."="Healthy.Life.Expectancy",
                                  "Trust..Government.Corruption."="Perceptions.of.Corruption",
                                  "Family"="Social.Support"))
colnames(WHRdata_cleaned)
```

checking all the data details incluidng missing values.

```{r}

skimr::skim_without_charts(WHRdata_cleaned)
```

# Data

```{r}
DT::datatable(WHRdata_cleaned, class= "compact")
```

export the dataset to csv file

```{r}
write_csv(WHRdata_cleaned, file = "World Happiness Data (2015-2019)_cleaned.csv")
```
